{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, BitsAndBytesConfig, MPNetPreTrainedModel, MPNetModel\n",
    "import torch\n",
    "import re\n",
    "import json\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from torch.utils.data import DataLoader\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import OrderedDict\n",
    "\n",
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "login(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=\"auto\", quantization_config=quant_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"\"\n",
    "name = f\"{data_path}/pdf_{0}_processed.txt\"\n",
    "with open(name, \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "pattern = re.compile(r'(?s)(#.*?\\n.*?\\S)(?=\\s*#|$)') # Matches each header sections.\n",
    "subs = pattern.findall(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The ESG-BERT Model to be Used.\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "        token_embeddings = model_output #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "# Definition of ESGify class because of custom,sentence-transformers like, mean pooling function and classifier head\n",
    "class ESGify(MPNetPreTrainedModel):\n",
    "    \"\"\"Model for Classification ESG risks from text.\"\"\"\n",
    "\n",
    "    def __init__(self,config): #tuning only the head\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__(config)\n",
    "        # Instantiate Parts of model\n",
    "        self.mpnet = MPNetModel(config,add_pooling_layer=False)\n",
    "        self.id2label =  config.id2label\n",
    "        self.label2id =  config.label2id\n",
    "        self.classifier = torch.nn.Sequential(OrderedDict([('norm',torch.nn.BatchNorm1d(768)),\n",
    "                                                ('linear',torch.nn.Linear(768,512)),\n",
    "                                                ('act',torch.nn.ReLU()),\n",
    "                                                ('batch_n',torch.nn.BatchNorm1d(512)),\n",
    "                                                ('drop_class', torch.nn.Dropout(0.2)),\n",
    "                                                ('class_l',torch.nn.Linear(512 ,47))]))\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "         # Feed input to mpnet model\n",
    "        outputs = self.mpnet(input_ids=input_ids,\n",
    "                             attention_mask=attention_mask)\n",
    "\n",
    "        # mean pooling dataset and eed input to classifier to compute logits\n",
    "        logits = self.classifier( mean_pooling(outputs['last_hidden_state'],attention_mask))\n",
    "\n",
    "        # apply sigmoid\n",
    "        logits  = 1.0 / (1.0 + torch.exp(-logits))\n",
    "        return logits\n",
    "esg_model = ESGify.from_pretrained('ai-lab/ESGify')\n",
    "esg_tokenizer = AutoTokenizer.from_pretrained('ai-lab/ESGify')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esg_classify(sub_splitted):\n",
    "    res = []\n",
    "    for para in sub_splitted:\n",
    "        to_model = esg_tokenizer.batch_encode_plus(\n",
    "                      [para],\n",
    "                      add_special_tokens=True,\n",
    "                      max_length=512,\n",
    "                      return_token_type_ids=False,\n",
    "                      padding=\"max_length\",\n",
    "                      truncation=True,\n",
    "                      return_attention_mask=True,\n",
    "                      return_tensors='pt',\n",
    "                    )\n",
    "        results = esg_model(**to_model)\n",
    "        for i in torch.topk(results, k=1).indices.tolist()[0]:\n",
    "            res.append(esg_model.id2label[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All categories predicted by ESG-BERT\n",
    "topics = {\n",
    "    'Air Pollution': 'Environmental - Air Pollution',\n",
    "    'Animal Welfare': 'Environmental - Animal Welfare',\n",
    "    'Biodiversity': 'Environmental - Biodiversity',\n",
    "    'Climate Risks': 'Environmental - Climate Risks',\n",
    "    'Communities Health and Safety': 'Social - Communities Health and Safety',\n",
    "    'Corporate Governance': 'Governance - Corporate Governance',\n",
    "    'Cultural Heritage': 'Social - Cultural Heritage',\n",
    "    'Data Safety': 'Social - Data Safety',\n",
    "    'Disclosure': 'Governance - Disclosure',\n",
    "    'Discrimination': \"Social - Discrimination\",\n",
    "    'Economic Crime': 'Governance - Economic Crime',\n",
    "    'Emergencies (Environmental)': 'Environmental - Emergencies',\n",
    "    'Emergencies (Social)': 'Social - Emergencies',\n",
    "    'Employee Health and Safety': 'Social - Employee Health and Safety',\n",
    "    'Energy Efficiency and Renewables': 'Environmental - Energy Efficiency and Renewables',\n",
    "    'Environmental Management': 'Environmental - Environmental Management',\n",
    "    'Forced Labour': 'Social - Forced Labor',\n",
    "    'Freedom of Association and Right to Organise': 'Social - Freedom of Association and Right to Organise',\n",
    "    'Greenhouse Gas Emissions': 'Environmental - Greenhouse Gas Emissions',\n",
    "    'Hazardous Materials Management': 'Environmental - Hazardous Material Management',\n",
    "    'Human Rights': 'Social - Human Rights',\n",
    "    'Indigenous People': 'Social - Indigenous People',\n",
    "    'Labor Relations Management': 'Social - Labor Relations Management',\n",
    "    'Land Acquisition and Resettlement (E)': 'Environmental - Land Acquisition and Resettlement',\n",
    "    'Land Acquisition and Resettlement (S)': 'Social - Land Acquisition and Resettlement',\n",
    "    'Land Rehabilitation': 'Environmental - Land Rehabilitation',\n",
    "    'Landscape Transformation': 'Environmental - Land Transformation',\n",
    "    'Legal Proceedings & Law Violations': 'Governance - Legal Proceedings & Law Violations',\n",
    "    'Minimum Age and Child Labour': 'Social - Minimum Age and Child Labor',\n",
    "    'Natural Resources': 'Environmental - Natural Resources',\n",
    "    'Not Relevant to ESG': 'Not Relevant to ESG - NA',\n",
    "    'Physical Impacts': 'Environmental - Physical Impacts',\n",
    "    'Planning Limitations': 'Environmental - Planning Limitations',\n",
    "    'Product Safety and Quality': 'Social - Product Safety and Quality',\n",
    "    'Responsible Investment & Greenwashing': 'Governance - Responsible Investment & Greenwashing',\n",
    "    'Retrenchment': 'Social - Retrenchment',\n",
    "    'Risk Management and Internal Control': 'Governance - Risk Management and Internal Control',\n",
    "    'Soil and Groundwater Impact': 'Environmental - Soil and Groundwater Impact',\n",
    "    'Strategy Implementation': 'Governance - Strategy Implementation',\n",
    "    'Supply Chain (Economic / Governance)': 'Governance - Supply Chain (Economic / Governance)',\n",
    "    'Supply Chain (Environmental)': 'Environmental - Supply Chain',\n",
    "    'Supply Chain (Social)': 'Social - Supply Chain',\n",
    "    'Surface Water Pollution': 'Environmental - Surface Water Pollution', \n",
    "    'Values and Ethics': 'Governance - Values and Ethics',\n",
    "    'Waste Management': 'Environmental - Waste Management',\n",
    "    'Wastewater Management': 'Environmental - Wastewater Management',\n",
    "    'Water Consumption': 'Environmental - Water Consumption'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_body = f\"\"\"You are provided with three inputs:\n",
    " - paragraph: The paragraph in focus.\n",
    " - context: The surrounding text that includes the paragraph itself (i.e., the actual portions of text around the paragraph, not a summary).\n",
    " - topic: The predicted topic for the paragraph.\n",
    "\n",
    "The possible predicted topics are: {topics.keys()}\n",
    "\n",
    "Task:\n",
    "Using the provided context (which includes the paragraph itself) and the predicted topic, determine if the paragraph is related to ESG (Environmental, Social, Governance) issues.\n",
    " - Output \"ESG\" if the paragraph is related to ESG.\n",
    " - Output \"Non-ESG\" if the paragraph is not related to ESG.\n",
    "\n",
    "Important:\n",
    " - The predicted topic is a hint; however, it may not always be accurate—especially if the paragraph contains HTML, LaTeX, or other non-standard formats.\n",
    " - Your output must be exactly either \"ESG\" or \"Non-ESG\" without any additional commentary, text, or extra whitespace.\n",
    "\n",
    "Example 1:\n",
    "'''\n",
    "Input = \n",
    "paragraph: \"The company has implemented a new system to monitor greenhouse gas emissions more efficiently.\"\n",
    "context: \"In this feature article, the company’s environmental initiatives are discussed in detail. The company has implemented a new system to monitor greenhouse gas emissions more efficiently.\"\n",
    "topic: \"Environmental - Greenhouse Gas Emissions\"\n",
    "\n",
    "Output = \n",
    "ESG\n",
    "'''\n",
    "\n",
    "Example 2:\n",
    "'''\n",
    "Input = \n",
    "paragraph: \"The latest model of the smartphone offers a vibrant display and a sleek design.\"\n",
    "context: \"The review covers various aspects of the new smartphone. The latest model of the smartphone offers a vibrant display and a sleek design.\"\n",
    "topic: \"Not Relevant to ESG - NA\"\n",
    "\n",
    "Output = \n",
    "Non-ESG\n",
    "'''\n",
    "\n",
    "Example 3:\n",
    "'''\n",
    "Input = \n",
    "paragraph: \"A community safety initiative was launched to improve local neighborhood security.\"\n",
    "context: \"The news report details several local programs. A community safety initiative was launched to improve local neighborhood security.\"\n",
    "topic: \"Social - Communities Health and Safety\"\n",
    "\n",
    "Output = \n",
    "ESG\n",
    "'''\n",
    "\n",
    "Now, here is the input that you need to classify:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = []\n",
    "pattern = re.compile(r\"\\bNon-ESG\\b|\\bESG\\b\")\n",
    "for sub in subs[:10]:\n",
    "    sub_splitted = sub.split(\"\\n\\n\")\n",
    "    esg_topics = esg_classify(sub_splitted)\n",
    "    for i, para in enumerate(sub_splitted):\n",
    "        msg = message_body + \"paragraph: \" + para + \"\\n\" + \"context: \" + sub + \"\\n\" + \"topic: \" + esg_topics[i]\n",
    "        if tokenizer.pad_token_id is None:\n",
    "            tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "            model.config.pad_token_id = tokenizer.pad_token_id\n",
    "        messages = [{'role': 'user', 'content': msg}]\n",
    "        inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", return_attention_mask=True).to(\"cuda\")\n",
    "        outputs = model.generate(inputs, max_new_tokens=100000)\n",
    "        res = tokenizer.decode(outputs[0]).split(\"<|end_header_id|>\")[-1].strip(\"\\n\").strip(\"<|eot_id|>\")\n",
    "        res = pattern.findall(res)[0]\n",
    "        op.append([para, res])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below is a another prompt that predicts, E, S, G, or None, rather than ESG vs. None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_body = f\"\"\"You are provided with three inputs:\n",
    " - paragraph: The paragraph in focus.\n",
    " - context: The surrounding text that includes the paragraph itself (i.e., the actual portions of text around the paragraph, not a summary).\n",
    " - topic: The predicted topic for the paragraph.\n",
    "\n",
    "The possible predicted topics are: {topics.values()}\n",
    "\"\"\"\n",
    "message_body +=\"\"\"\n",
    "Task:\n",
    "Using the provided context (which includes the paragraph itself) and the predicted topics, determine if the paragraph is related to ESG (Environmental, Social, Governance) issues. For this task, evaluate each ESG factor separately:\n",
    " - \"E\" for Environmental\n",
    " - \"S\" for Social\n",
    " - \"G\" for Governance\n",
    "\n",
    "If the paragraph is related to one or more ESG factors, mark the corresponding keys as true. If the paragraph is not related to any ESG factors, mark \"N\" (for Non-ESG) as true and the ESG keys as false.\n",
    "\n",
    "Return your result as a JSON object exactly in the following format:\n",
    "{\"E\": <boolean>, \"S\": <boolean>, \"G\": <boolean>, \"N\": <boolean>}\n",
    "\n",
    "Important:\n",
    " - The predicted topics are only hints; they might not always be accurate—especially if the paragraph contains HTML, LaTeX, or other non-standard formats.\n",
    " - Your output must be exactly in the JSON format with the specified keys and boolean values, with no additional commentary, text, or extra whitespace.\n",
    "\n",
    "Examples:\n",
    "\n",
    "Example 1:\n",
    "'''\n",
    "Input = \n",
    "paragraph: \"The company has implemented a new system to monitor greenhouse gas emissions more efficiently.\"\n",
    "context: \"In this feature article, the company’s environmental initiatives are discussed in detail. The company has implemented a new system to monitor greenhouse gas emissions more efficiently.\"\n",
    "topic: \"Environmental - Greenhouse Gas Emissions\"\n",
    "\n",
    "Output = \n",
    "{\"E\": true, \"S\": false, \"G\": false, \"N\": false}\n",
    "'''\n",
    "\n",
    "Example 2:\n",
    "'''\n",
    "Input = \n",
    "paragraph: \"The latest model of the smartphone offers a vibrant display and a sleek design.\"\n",
    "context: \"The review covers various aspects of the new smartphone. The latest model of the smartphone offers a vibrant display and a sleek design.\"\n",
    "topic: \"Not Relevant to ESG - NA\"\n",
    "\n",
    "Output = \n",
    "{\"E\": false, \"S\": false, \"G\": false, \"N\": true}\n",
    "'''\n",
    "\n",
    "Example 3:\n",
    "'''\n",
    "Input = \n",
    "paragraph: \"A community safety initiative was launched to improve local neighborhood security.\"\n",
    "context: \"The news report details several local programs. A community safety initiative was launched to improve local neighborhood security.\"\n",
    "topic: \"Social - Communities Health and Safety\"\n",
    "\n",
    "Output = \n",
    "{\"E\": false, \"S\": true, \"G\": false, \"N\": false}\n",
    "'''\n",
    "\n",
    "Now, here is the input that you need to classify:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = []\n",
    "for sub in subs[:1]:\n",
    "    sub_splitted = sub.split(\"\\n\\n\")\n",
    "    esg_topics = esg_classify(sub_splitted)\n",
    "    for i, para in enumerate(sub_splitted):\n",
    "        msg = message_body + \"paragraph: \" + para + \"\\n\" + \"context: \" + sub + \"\\n\" + \"topic: \" + topics[esg_topics[i]]\n",
    "        if tokenizer.pad_token_id is None:\n",
    "            tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "            model.config.pad_token_id = tokenizer.pad_token_id\n",
    "        messages = [{'role': 'user', 'content': msg}]\n",
    "        inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", return_attention_mask=True).to(\"cuda\")\n",
    "        outputs = model.generate(inputs, max_new_tokens=100000)\n",
    "        res = tokenizer.decode(outputs[0]).split(\"<|end_header_id|>\")[-1].strip(\"\\n\").strip(\"<|eot_id|>\")\n",
    "        res = re.findall(\"{.+}\", res, re.DOTALL)[0]\n",
    "        res = re.sub('\\s', \"\", res)\n",
    "        res = json.loads(res)\n",
    "        op.append([para, topics[esg_topics[i]], res])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
