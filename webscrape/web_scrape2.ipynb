{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "from urllib.parse import urljoin\n",
    "import shutil\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.common.exceptions import TimeoutException, StaleElementReferenceException, NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def get_automotive_industry():\n",
    "    # Step 1: Get the urls for all sectors.\n",
    "    response = requests.get(\"https://sustainabilityreports.com/sectors/\")\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    sectors_url = [i['href'] for i in soup.find_all('a', href=re.compile(r'https://sustainabilityreports.com/sector/[a-z\\\\-]+'))]\n",
    "\n",
    "    # Step 2: \n",
    "    industry_link = []\n",
    "    for sector_url in sectors_url:\n",
    "        companies = set()\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('--headless')\n",
    "        options.add_argument('--disable-gpu')\n",
    "        options.add_argument('--no-sandbox')\n",
    "        options.add_argument('--disable-dev-shm-usage')\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.maximize_window()\n",
    "        try:\n",
    "            driver.get(sector_url)\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, 'a[href^=\"https://sustainabilityreports.com/company/\"]'))\n",
    "            )\n",
    "            scroll_count = 0\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            scroll_limit = 2000\n",
    "            while True:\n",
    "                if scroll_limit and scroll_count >= scroll_limit:\n",
    "                    print(f\"Reached maximum scroll limit of {scroll_limit}\")\n",
    "                    break\n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                items = soup.find_all(\"a\", href=re.compile(r'https://sustainabilityreports.com/company/[a-z\\\\-]+/'))\n",
    "                for item in items:\n",
    "                    companies.add(item['href'])\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(4)\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "                scroll_count += 1\n",
    "        except TimeoutException:\n",
    "            print(\"Timeout waiting for elements to load\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {str(e)}\")\n",
    "        finally:\n",
    "            driver.quit()\n",
    "        companies = list(companies)\n",
    "        counter = 1\n",
    "        for company in companies:\n",
    "            response = requests.get(company)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            industry = soup.find(\"a\", href=re.compile(r'https://sustainabilityreports.com/industry/[a-z\\\\-]+/'))\n",
    "            if industry['href'] not in industry_link:\n",
    "                industry_link.append(industry['href'])\n",
    "                counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "from urllib.parse import urljoin\n",
    "import shutil\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.common.exceptions import TimeoutException, StaleElementReferenceException, NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://sustainabilityreports.com/sectors/\")\n",
    "response.raise_for_status()\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "sectors_url = [i['href'] for i in soup.find_all('a', href=re.compile(r'https://sustainabilityreports.com/sector/[a-z\\\\-]+'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking sector: https://sustainabilityreports.com/sector/transportation-and-warehousing/\n",
      "\n",
      "\n",
      "Checking sector: https://sustainabilityreports.com/sector/utilities/\n",
      "Found 2 Distinct Industries\n",
      "\n",
      "Checking sector: https://sustainabilityreports.com/sector/wholesale-trade/\n",
      "Found 18 Distinct Industries\n",
      "\n"
     ]
    }
   ],
   "source": [
    "industry_link = []\n",
    "for sector_url in sectors_url:\n",
    "    companies = set()\n",
    "    print(\"Checking sector:\", sector_url)\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.maximize_window()\n",
    "    try:\n",
    "        driver.get(sector_url)\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'a[href^=\"https://sustainabilityreports.com/company/\"]'))\n",
    "        )\n",
    "        scroll_count = 0\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        scroll_limit = 2000\n",
    "        while True:\n",
    "            if scroll_limit and scroll_count >= scroll_limit:\n",
    "                print(f\"Reached maximum scroll limit of {scroll_limit}\")\n",
    "                break\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            items = soup.find_all(\"a\", href=re.compile(r'https://sustainabilityreports.com/company/[a-z\\\\-]+/'))\n",
    "            for item in items:\n",
    "                companies.add(item['href'])\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(4)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "            scroll_count += 1\n",
    "    except TimeoutException:\n",
    "        print(\"Timeout waiting for elements to load\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    companies = list(companies)\n",
    "    counter = 1\n",
    "    for company in companies:\n",
    "        response = requests.get(company)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        industry = soup.find(\"a\", href=re.compile(r'https://sustainabilityreports.com/industry/[a-z\\\\-]+/'))\n",
    "        if industry['href'] not in industry_link:\n",
    "            industry_link.append(industry['href'])\n",
    "            print(f\"\\rFound {counter} Distinct Industries\", end=\"\", flush=True)\n",
    "            counter += 1\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_link = pd.unique(pd.Series(industry_link)).tolist()\n",
    "for link in industry_link:\n",
    "    with open(\"../sr_data/industry.txt\", 'a') as file:\n",
    "        file.write(link + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_link = []\n",
    "with open(\"../sr_data/industry.txt\", 'r') as file:\n",
    "    for line in file:\n",
    "        industry_link.append(line.strip(\"\\n\"))\n",
    "industries = [link.split(\"/industry/\")[1].strip(\"/\") for link in industry_link]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "automotive_industries = [\n",
    "    \"motor-vehicle-parts-manufacturing\",\n",
    "    \"motor-vehicle-manufacturing\",\n",
    "    \"motor-vehicle-body-and-trailer-manufacturing\",\n",
    "    \"automotive-repair-and-maintenance\",\n",
    "    \"automotive-equipment-rental-and-leasing\",\n",
    "    \"automotive-parts-accessories-and-tire-retailers\",\n",
    "    \"motor-vehicle-and-motor-vehicle-parts-and-supplies-merchant-wholesalers\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "automotive_links = [\"https://sustainabilityreports.com/industry/\" + industry for industry in automotive_industries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking industry: https://sustainabilityreports.com/industry/motor-vehicle-parts-manufacturing\n",
      "Checking industry: https://sustainabilityreports.com/industry/motor-vehicle-manufacturing\n",
      "Checking industry: https://sustainabilityreports.com/industry/motor-vehicle-body-and-trailer-manufacturing\n",
      "Checking industry: https://sustainabilityreports.com/industry/automotive-repair-and-maintenance\n",
      "Checking industry: https://sustainabilityreports.com/industry/automotive-equipment-rental-and-leasing\n",
      "Checking industry: https://sustainabilityreports.com/industry/automotive-parts-accessories-and-tire-retailers\n",
      "Checking industry: https://sustainabilityreports.com/industry/motor-vehicle-and-motor-vehicle-parts-and-supplies-merchant-wholesalers\n"
     ]
    }
   ],
   "source": [
    "companies = []\n",
    "download_dests = []\n",
    "for automotive_url in automotive_links:\n",
    "    print(\"Checking industry:\", automotive_url)\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.maximize_window()\n",
    "    try:\n",
    "        driver.get(automotive_url)\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'a[href^=\"https://sustainabilityreports.com/company/\"]'))\n",
    "        )\n",
    "        scroll_count = 0\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        scroll_limit = 2000\n",
    "        while True:\n",
    "            if scroll_limit and scroll_count >= scroll_limit:\n",
    "                print(f\"Reached maximum scroll limit of {scroll_limit}\")\n",
    "                break\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            items = soup.find_all(\"a\", href=re.compile(r'https://sustainabilityreports.com/company/[a-z\\\\-]+/'))\n",
    "            for item in items:\n",
    "                if item['href'] not in companies:\n",
    "                    companies.append(item['href'])\n",
    "                    download_dests.append(f\"../sr_data/{automotive_url.split('/industry/')[-1]}/{item['href'].split('/company/')[-1]}\")\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(4)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "            scroll_count += 1\n",
    "    except TimeoutException:\n",
    "        print(\"Timeout waiting for elements to load\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrieve_url(url, email_address):\n",
    "    pdf_url = ''\n",
    "    report_name = ''\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        report = soup.find(\"a\", href=re.compile(r'https://sustainabilityreports.com/reports/[a-z\\\\-]+'))\n",
    "        report_name = report.text.strip() + '.pdf'\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        # Step 1: Wait for the first \"Download PDF\" button to be clickable and click it.\n",
    "        download_pdf_btn = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable(\n",
    "                (By.XPATH, \"//a[contains(text(), 'Download PDF') and contains(@class, 'wpdm-download-link')]\")\n",
    "            )\n",
    "        )\n",
    "        download_pdf_btn.click()\n",
    "        print(f\"\\rClicked the initial Download PDF button.\", end=\"\", flush=True)\n",
    "\n",
    "        # Wait for the iframe containing the popup to load.\n",
    "        # Adjust the XPath below based on your page. This example assumes the iframe's src contains \"popup\".\n",
    "        iframe = WebDriverWait(driver, 15).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.XPATH, \"//iframe[contains(@src, 'wpdm')]\")\n",
    "            )\n",
    "        )\n",
    "        # Switch into the iframe context\n",
    "        driver.switch_to.frame(iframe)\n",
    "        print(f\"\\rSwitched to the iframe containing the checkbox.\", end=\"\", flush=True)\n",
    "\n",
    "        # Step 2: Wait for the checkbox to be clickable and then click it.\n",
    "        checkbox = WebDriverWait(driver, 15).until(\n",
    "            EC.element_to_be_clickable(\n",
    "                (By.XPATH, \"//input[contains(@class, 'terms_checkbox') and @type='checkbox']\")\n",
    "            )\n",
    "        )\n",
    "        checkbox.click()\n",
    "        print(f\"\\rCheckbox clicked.\", end=\"\", flush=True)\n",
    "\n",
    "        # Step 3: Check if an email input appears. If so, fill it in and click Submit.\n",
    "        try:\n",
    "            email_input = WebDriverWait(driver, 10).until(\n",
    "                EC.visibility_of_element_located((By.XPATH, \"//input[@type='email']\"))\n",
    "            )\n",
    "            email_input.send_keys(email_address)\n",
    "            print(f\"\\rEmail entered.\", end=\"\", flush=True)\n",
    "\n",
    "            submit_btn = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable(\n",
    "                    (By.XPATH, \"//button[contains(@id, 'wpdm_submit') and contains(text(), 'Submit')]\")\n",
    "                )\n",
    "            )\n",
    "            submit_btn.click()\n",
    "            print(\"Submit button clicked.\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\rEmail input not required, skipping email submission.\", end=\"\", flush=True)\n",
    "\n",
    "        # Step 4: Wait for the final download link to appear in the main content and retrieve its href.\n",
    "        download_link = WebDriverWait(driver, 15).until(\n",
    "            EC.element_to_be_clickable(\n",
    "                (By.XPATH, \"//a[contains(text(), 'Download PDF')]\")\n",
    "            )\n",
    "        )\n",
    "        pdf_url = download_link.get_attribute(\"href\")\n",
    "        print(f\"\\rDownload link found: {pdf_url}\", end=\"\", flush=True)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "    finally:\n",
    "        driver.quit()\n",
    "        return (pdf_url, report_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf(url, output_path):\n",
    "    try:\n",
    "        output_dir = os.path.dirname(output_path)\n",
    "        if output_dir and not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        with open(output_path, 'wb') as pdf_file:\n",
    "            pdf_file.write(response.content)\n",
    "        with open(\"../sr_data/SustainabilityReports.txt\", 'a') as file:\n",
    "            file.write(f\"Industry: {output_path.split(\"/\")[2]}, Company: {output_path.split(\"/\")[3]}\\n\")\n",
    "        with open(\"../sr_data/pdf_reports_urls.txt\", 'a') as file:\n",
    "            file.write(url+'\\n')\n",
    "        return True\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error downloading the PDF: {e}\")\n",
    "        return False\n",
    "    except IOError as e:\n",
    "        print(f\"Error saving the PDF: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for idx, company_url in enumerate(companies):\n",
    "    email_address = 'example@email.com'\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=chrome_options, service=ChromeService())\n",
    "    pdf_url, report_name = retrieve_url(company_url, email_address)\n",
    "    if pdf_url != '':\n",
    "        download_pdf(pdf_url, download_dests[idx] + \"/\" + report_name)\n",
    "    print(f\"\\rProcessed {idx+1}/{len(companies)} reports.\", end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
